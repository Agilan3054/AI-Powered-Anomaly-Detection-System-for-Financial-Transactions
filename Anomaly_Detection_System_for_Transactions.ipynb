{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare the Dataset**"
      ],
      "metadata": {
        "id": "Afe9P1qV7jHp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ciq4HCUW7CRB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Generate a synthetic dataset for financial transactions\n",
        "np.random.seed(42)\n",
        "\n",
        "data = {\n",
        "    'transaction_id': np.arange(1, 10001),\n",
        "    'amount': np.random.uniform(1, 10000, 10000),\n",
        "    'transaction_type': np.random.choice(['withdrawal', 'deposit', 'transfer'], 10000),\n",
        "    'oldbalanceOrg': np.random.uniform(0, 10000, 10000),\n",
        "    'newbalanceOrig': np.random.uniform(0, 10000, 10000),\n",
        "    'oldbalanceDest': np.random.uniform(0, 10000, 10000),\n",
        "    'newbalanceDest': np.random.uniform(0, 10000, 10000)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create a label column for anomalies (fraudulent transactions)\n",
        "df['is_fraud'] = np.random.choice([0, 1], size=(10000,), p=[0.98, 0.02])  # Simulate 2% fraud cases\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering**"
      ],
      "metadata": {
        "id": "Y9w3_Pzr7kNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering: creating new features\n",
        "df['transaction_change'] = df['newbalanceOrig'] - df['oldbalanceOrg']\n",
        "df['dest_change'] = df['newbalanceDest'] - df['oldbalanceDest']\n",
        "\n",
        "# Convert categorical feature 'transaction_type' into dummy variables\n",
        "df = pd.get_dummies(df, columns=['transaction_type'], drop_first=True)\n",
        "\n",
        "# Drop columns that won't be used in the model\n",
        "df.drop(['transaction_id'], axis=1, inplace=True)\n",
        "\n",
        "# Split the dataset into features and labels\n",
        "X = df.drop(['is_fraud'], axis=1)\n",
        "y = df['is_fraud']\n"
      ],
      "metadata": {
        "id": "t7SCJVCo7FwX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autoencoder for Anomaly Detection**"
      ],
      "metadata": {
        "id": "aXfhygdc7k2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Split the dataset into training (only non-fraud data) and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Using only non-fraudulent data for training the autoencoder\n",
        "X_train_normal = X_train[y_train == 0]\n",
        "\n",
        "# Autoencoder model\n",
        "autoencoder = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(X_train.shape[1], activation='sigmoid')\n",
        "])\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.fit(X_train_normal, X_train_normal, epochs=10, batch_size=64, validation_data=(X_test, X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFQjYSvL7Hu6",
        "outputId": "1f332842-9774-44a8-e5fe-20b6211c3f61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 22258240.0000 - val_loss: 22006508.0000\n",
            "Epoch 2/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 22163226.0000 - val_loss: 22005582.0000\n",
            "Epoch 3/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 22293392.0000 - val_loss: 22004670.0000\n",
            "Epoch 4/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 22121462.0000 - val_loss: 22004198.0000\n",
            "Epoch 5/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 22061412.0000 - val_loss: 22004188.0000\n",
            "Epoch 6/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 22201930.0000 - val_loss: 22004176.0000\n",
            "Epoch 7/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 22308868.0000 - val_loss: 22004152.0000\n",
            "Epoch 8/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 22326366.0000 - val_loss: 22004150.0000\n",
            "Epoch 9/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 22414852.0000 - val_loss: 22004138.0000\n",
            "Epoch 10/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 22171674.0000 - val_loss: 22004128.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78dd4963efe0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Isolation Forest Model**"
      ],
      "metadata": {
        "id": "0ln9GYYH7lpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Train Isolation Forest\n",
        "isolation_forest = IsolationForest(contamination=0.02, random_state=42)\n",
        "isolation_forest.fit(X_train)\n",
        "\n",
        "# Predict anomalies\n",
        "y_pred_if = isolation_forest.predict(X_test)\n",
        "y_pred_if = np.where(y_pred_if == -1, 1, 0)  # Convert -1 to 1 for anomaly\n"
      ],
      "metadata": {
        "id": "WkzuNW5K7KoG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-Class SVM Model**"
      ],
      "metadata": {
        "id": "8Y8Ls7Ew7mha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "# Train One-Class SVM\n",
        "ocsvm = OneClassSVM(kernel='rbf', gamma=0.001, nu=0.05)\n",
        "ocsvm.fit(X_train_normal)\n",
        "\n",
        "# Predict anomalies\n",
        "y_pred_svm = ocsvm.predict(X_test)\n",
        "y_pred_svm = np.where(y_pred_svm == -1, 1, 0)\n"
      ],
      "metadata": {
        "id": "dvqnkF2k7NLu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Risk Scoring System**"
      ],
      "metadata": {
        "id": "VPjc8j-47nNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine predictions from all models (Autoencoder, Isolation Forest, One-Class SVM)\n",
        "y_pred_autoencoder = autoencoder.predict(X_test)\n",
        "mse = np.mean(np.power(X_test - y_pred_autoencoder, 2), axis=1)\n",
        "y_pred_ae = np.where(mse > np.percentile(mse, 98), 1, 0)\n",
        "\n",
        "# Average the results from all models for a final risk score\n",
        "risk_score = (y_pred_if + y_pred_svm + y_pred_ae) / 3.0\n",
        "\n",
        "# Define a risk threshold (you can fine-tune this based on the distribution)\n",
        "risk_threshold = 0.5\n",
        "y_final_pred = np.where(risk_score > risk_threshold, 1, 0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOu-M_l47PYX",
        "outputId": "81f586ea-912a-49d2-ebc3-8d015ad7e221"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**"
      ],
      "metadata": {
        "id": "dr6AAiZ77n3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Confusion Matrix and Classification Report\n",
        "conf_matrix = confusion_matrix(y_test, y_final_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_final_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJJNV04R7SCe",
        "outputId": "ff87651e-1497-441f-cb01-642c014b1b8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[1890   73]\n",
            " [  36    1]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97      1963\n",
            "           1       0.01      0.03      0.02        37\n",
            "\n",
            "    accuracy                           0.95      2000\n",
            "   macro avg       0.50      0.49      0.49      2000\n",
            "weighted avg       0.96      0.95      0.95      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aUXEhfNr7bLF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}